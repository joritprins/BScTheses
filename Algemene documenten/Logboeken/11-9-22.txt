Machine learning:
1. import data
2. clean the data (inacurate, incomplete, duplicate, etc.)
3. split the data into training/test sets (about 80/20)
4. create model
5. train model (with algorithms)
6. make predictions
7. evaluate and improve (use other algorithm, feed more data)

Libraries
scikit-learn - machine learning, decision trees, algorithms

kaggle.com for datasets -> video games sales

Binary tree, condition -> true = left tree, false = right tree


Boolean classifier : 0 of 1\
Bayes classification X1 ... Xn -> [] -> Y
				  ^ P(X1=x1, X2=x2, ... Xn=xn | Y = y) of p_X1..Xn | Y = y^(x1, x2, ... , xn) = Probability mass function (22:11 eerste college week 2)

We willen berekenen classify(x1, ..., xn) = argmax_y P(Y=y | X1=x1, ..., Xn = xn)
Gegeven dataset X (x1, ..., xn) is de kans dan hoger op 0 of 1 (P(Y=y | X1=x1, ..., Xn = xn))
classify(x1, ..., xn) = argmax_y  (    ( P(X1=x1, ..., Xn = xn | Y = y)*P(Y=y) )  /  ( P(X1=x1, ..., Xn = xn) )      ) 
P(X1=x1, ..., Xn = xn | Y = y)	= class conditional prob of the data
P(Y=y)				= a priori probability of classes
P(X1=x1, ..., Xn = xn)		= evidence, en onafhankelijk van y, dus voor de argmax kunne we deze weghalen. De waarde is dan anders maar dan gemultipliceert

Omdat deler onafhankelijk is van y kunnen we de (descrete) Bayes Classifier maken:
classify(x1, ..., xn) = argmax_y  (    P(X1=x1, ..., Xn = xn | Y = y)*P(Y=y)   ) 
P(X1=x1, ..., Xn = xn | Y = y) heeft veel mogelijkheden: 
00..001
00..010
00..011
00..100, etc -> 2^(n+1) + 2 (a priori kansen). Voor een grote dataset wordt dit onmogelijk uit te rekenen. 
Omdat ze onafhankelijk zijn kunnen we het ook per woord berekenen


Securing Machine Learning in the cloud: a systemattic review of cloud machine learning security (https://www.frontiersin.org/articles/10.3389/fdata.2020.587139/full) 